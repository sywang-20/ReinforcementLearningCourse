{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stable-baselines3.readthedocs.io/en/master/guide/rl.html\n",
    "# https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#a-taxonomy-of-rl-algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stable-baselines3[extra]\n",
      "  Downloading stable_baselines3-2.0.0-py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied: cloudpickle in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from stable-baselines3[extra]) (2.2.0)\n",
      "Requirement already satisfied: matplotlib in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from stable-baselines3[extra]) (3.3.3)\n",
      "Requirement already satisfied: pandas in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from stable-baselines3[extra]) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from stable-baselines3[extra]) (4.5.0)\n",
      "Requirement already satisfied: torch>=1.11 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: tqdm in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from stable-baselines3[extra]) (4.64.1)\n",
      "Requirement already satisfied: psutil in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from stable-baselines3[extra]) (5.9.1)\n",
      "Requirement already satisfied: pillow in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from stable-baselines3[extra]) (8.1.0)\n",
      "Collecting gymnasium==0.28.1\n",
      "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
      "Collecting autorom[accept-rom-license]~=0.6.0\n",
      "  Downloading AutoROM-0.6.1-py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: requests in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (2.25.1)\n",
      "Requirement already satisfied: click in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (7.1.2)\n",
      "Collecting farama-notifications>=0.0.1\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Collecting importlib-metadata>=4.8.0\n",
      "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
      "Collecting jax-jumpy>=1.0.0\n",
      "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
      "Collecting numpy>=1.20\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-win_amd64.whl (14.0 MB)\n",
      "Collecting pygame<2.1.3,>=2.0\n",
      "  Downloading pygame-2.1.2-cp37-cp37m-win_amd64.whl (8.4 MB)\n",
      "Collecting shimmy[atari]~=0.2.1\n",
      "  Downloading Shimmy-0.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting ale-py~=0.8.1\n",
      "  Downloading ale_py-0.8.1-cp37-cp37m-win_amd64.whl (952 kB)\n",
      "Collecting tensorboard>=2.9.1\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "Requirement already satisfied: wheel>=0.26 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.36.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (49.6.0.post20210108)\n",
      "Collecting absl-py>=0.4\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: six>=1.9.0 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.15.0)\n",
      "Requirement already satisfied: urllib3<2.0 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.26.2)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.57.0-cp37-cp37m-win_amd64.whl (4.3 MB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "Collecting protobuf<4,>=3.9.2\n",
      "  Downloading protobuf-3.20.3-cp37-cp37m-win_amd64.whl (905 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from requests->autorom[accept-rom-license]~=0.6.0->stable-baselines3[extra]) (2022.12.7)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.3-cp37-cp37m-win_amd64.whl (17 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Collecting AutoROM.accept-rom-license\n",
      "  Downloading AutoROM.accept-rom-license-0.6.1.tar.gz (434 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting importlib-resources\n",
      "  Using cached importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.8.1)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.8.0.76-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Requirement already satisfied: pytz>=2017.3 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2020.5)\n",
      "Collecting rich\n",
      "  Downloading rich-13.5.2-py3-none-any.whl (239 kB)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0\n",
      "  Downloading Pygments-2.16.1-py3-none-any.whl (1.2 MB)\n",
      "Requirement already satisfied: colorama in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.4)\n",
      "Building wheels for collected packages: AutoROM.accept-rom-license\n",
      "  Building wheel for AutoROM.accept-rom-license (PEP 517): started\n",
      "  Building wheel for AutoROM.accept-rom-license (PEP 517): finished with status 'done'\n",
      "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.6.1-py3-none-any.whl size=446680 sha256=5b529d2b4a5ee4cd9fa4194508812534193a9bdd472b18166542138e7c7ddc29\n",
      "  Stored in directory: c:\\users\\11447\\appdata\\local\\pip\\cache\\wheels\\04\\58\\e9\\8031ac97e7a2042ddb15456614b07ab978bf41e9edb39783a4\n",
      "Successfully built AutoROM.accept-rom-license\n",
      "Installing collected packages: zipp, pyasn1, numpy, rsa, pyasn1-modules, oauthlib, jax-jumpy, importlib-metadata, farama-notifications, cachetools, requests-oauthlib, mdurl, MarkupSafe, importlib-resources, gymnasium, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, shimmy, pygments, protobuf, markdown-it-py, markdown, grpcio, google-auth-oauthlib, AutoROM.accept-rom-license, autorom, ale-py, absl-py, tensorboard, stable-baselines3, rich, pygame, opencv-python\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.19.5\n",
      "    Uninstalling numpy-1.19.5:\n",
      "      Successfully uninstalled numpy-1.19.5\n",
      "  Attempting uninstall: MarkupSafe\n",
      "    Found existing installation: MarkupSafe 1.1.1\n",
      "    Uninstalling MarkupSafe-1.1.1:\n",
      "      Successfully uninstalled MarkupSafe-1.1.1\n",
      "  Attempting uninstall: pygments\n",
      "    Found existing installation: Pygments 2.7.3\n",
      "    Uninstalling Pygments-2.7.3:\n",
      "      Successfully uninstalled Pygments-2.7.3\n",
      "Successfully installed AutoROM.accept-rom-license-0.6.1 MarkupSafe-2.1.3 absl-py-1.4.0 ale-py-0.8.1 autorom-0.6.1 cachetools-5.3.1 farama-notifications-0.0.4 google-auth-2.22.0 google-auth-oauthlib-0.4.6 grpcio-1.57.0 gymnasium-0.28.1 importlib-metadata-6.7.0 importlib-resources-5.12.0 jax-jumpy-1.0.0 markdown-3.4.4 markdown-it-py-2.2.0 mdurl-0.1.2 numpy-1.21.6 oauthlib-3.2.2 opencv-python-4.8.0.76 protobuf-3.20.3 pyasn1-0.5.0 pyasn1-modules-0.3.0 pygame-2.1.2 pygments-2.16.1 requests-oauthlib-1.3.1 rich-13.5.2 rsa-4.9 shimmy-0.2.1 stable-baselines3-2.0.0 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 werkzeug-2.2.3 zipp-3.15.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.18.0 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from gym) (1.21.6)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from gym) (2.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from gym) (6.7.0)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from importlib-metadata>=4.8.0->gym) (4.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages (from importlib-metadata>=4.8.0->gym) (3.15.0)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (PEP 517): started\n",
      "  Building wheel for gym (PEP 517): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827637 sha256=a9c2fb80563467bb59b9cb9d5172781f1a0cf4769646c7880516fa5caa62f9bf\n",
      "  Stored in directory: c:\\users\\11447\\appdata\\local\\pip\\cache\\wheels\\4d\\c8\\dc\\d08577bffa680f083f04448e81e4f176d0e45a13eb16f93c0c\n",
      "Successfully built gym\n",
      "Installing collected packages: gym-notices, gym\n",
      "Successfully installed gym-0.26.2 gym-notices-0.0.8\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "from stable_baselines3 import PPO  # import an algorithm\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv # import a wrapper\n",
    "from stable_baselines3.common.evaluation import evaluate_policy # import a wrapper for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"CartPole-v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages\\gym\\envs\\registration.py:556: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  f\"The environment {id} is out of date. You should consider \"\n"
     ]
    }
   ],
   "source": [
    "# Create the environment\n",
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\anaconda-install\\envs\\urbsim\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py:212: UserWarning: \u001b[33mWARN: You are calling render method without specifying any render mode. You can specify the render_mode at initialization, e.g. gym(\"CartPole-v0\", render_mode=\"rgb_array\")\u001b[0m\n",
      "  \"You are calling render method without specifying any render mode. \"\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-c07c36362924>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mn_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mscore\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[0mreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Episode:{} Score:{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "episodes = 5 # episode: one full game\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()  # set the environment to initial state\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        env.render() # view the environment\n",
    "        action = env.action_space.sample() # generate a random action\n",
    "        n_state, reward, done, info = env.step(action) # perform the action\n",
    "        score+=reward # update the score\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding The Environment\n",
    "https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0-push cart to left, 1-push cart to the right\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.1600966e+00,  2.3186252e+38, -3.5029808e-01, -8.3706835e+36],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [cart position, cart velocity, pole angle, pole angular velocity]\n",
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train an RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy', env, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save and Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_path = os.path.join('Training', 'Saved Models', 'PPO_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load('PPO_model', env=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    env.render()\n",
    "    if done: \n",
    "        print('info', info)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Viewing Logs in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_path = os.path.join(log_path, 'PPO_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir={training_log_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Adding a callback to the training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training', 'Saved Models')\n",
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=190, verbose=1)\n",
    "eval_callback = EvalCallback(env, \n",
    "                             callback_on_new_best=stop_callback, \n",
    "                             eval_freq=10000, \n",
    "                             best_model_save_path=save_path, \n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy', env, verbose = 1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join('Training', 'Saved Models', 'best_model')\n",
    "model = PPO.load(model_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Changing Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_arch=[dict(pi=[128, 128, 128, 128], vf=[128, 128, 128, 128])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy', env, verbose = 1, policy_kwargs={'net_arch': net_arch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Using an Alternate Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN('MlpPolicy', env, verbose = 1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn_path = os.path.join('Training', 'Saved Models', 'DQN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(dqn_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load(dqn_path, env=env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urbsim",
   "language": "python",
   "name": "urbsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
